SOZDAT TOPIC FROM COMMAND LINE:
docker container exec broker1 kafka-topics --create --bootstrap-server \localhost:9094 --topic kinaction_helloworld --partitions 3 --replication-factor 3
	ili
docker container exec 416 kafka-topics --create --bootstrap-server \localhost:9094 --topic kinaction_helloworld --partitions 3 --replication-factor 3
	broker1 		->	imja servic'a iz docker-compose file
	416 			-> 	docker container id
	kafka-topics	->	Чтобы создать topic, выполним в терминале команду kafka-topics с параметром --create,
	--partitions	->	определяет, на сколько partitions будет делиться topic. Например, мы предполагаем использовать три broker,
					поэтому, разбив тему на три раздела, дадим по одному разделу каждому брокеру.
	--replication-factor	->	Оно говорит, что в каждом разделе мы хотим иметь по три реплики (копии)
	--bootstrap-server	->	задает сетевой адрес брокера Kafka (eto znachenija iz docker-compose file)
	with zookeeper:
kafka-topics --zookeeper zookeeper:2181 --create --topic my_topic --partitions 3 --replication-factor 3
	--zookeeper		->	hostname from zookeeper in docker-compose file : zookeeper port in docker-compose file


DELETE TOPIC:
kafka-topics --zookeeper zookeeper:2181 --delete --topic my_topic


LIST OF AVAILABLE TOPICS:
docker container exec broker2 kafka-topics --list --bootstrap-server /localhost:9093
	ili
docker container exec 91657 kafka-topics --list --bootstrap-server /localhost:9093
	ili
docker container exec broker1 kafka-topics --list --bootstrap-server localhost:9092
	ili
docker container exec broker3 kafka-topics --list --bootstrap-server broker3:29094
	rabotaet lutsche esli zadawat ne nomer containera, a hostname iz docker-compose file, t.e. pokaziwaet tolko to chto nuzhno
	kafka-topics	->	komanda terminala
	--list		->	список всех имеющихся topic
	--bootstrap-server	->	 задает сетевой адрес брокера Kafka (eto znachenija iz docker-compose file)
	with zookeeper:
docker container exec 66e kafka-topics --zookeeper zookeeper:2181 --list
	--zookeeper		->	hostname from zookeeper in docker-compose file : zookeeper port in docker-compose file


DESCRIBE TOPIC:
docker container exec broker3 kafka-topics --describe --bootstrap-server localhost:9094 --topic kinaction_helloworld
	ili
docker container exec broker3 kafka-topics --describe --bootstrap-server broker3:29094 --topic kinaction_helloworld
	--describe	->	позволяет увидеть характеристики созданной темы
	Topic:kinaction_helloworld PartitionCount:3 ReplicationFactor:3 Configs:	->	краткие сведения об общем количестве разделов(partiotions) и реплик(replicas) на каждый раздел
	Isr	->	 расшифровывается как in-sync replicas – синхронизированные реплики. Синхронизированные реплики показывают, какие брокеры актуальны и не отстают от лидера.
	with zookeeper:
kafka-topic --zookeeper zookeeper:2181 --describe --topic my_topic


OTSILKA MESSAGES IN KAFKA: Команда запуска производителя Kafka:
kafka-console-producer --bootstrap-server broker3:29094 --topic kinaction_helloworld
	ili w docker:
docker container exec -it broker3 kafka-console-producer --bootstrap-server broker3:29094 --topic kinaction_helloworld
	ili with zookeeper (tak zarabotalo):
kafka-console-producer --broker-list kafka-broker-3:9092 --topic my_topic


POLUCHENIE MESSAGES FROM KAFKA: Команда запуска потребителя Kafka
docker container exec -it broker3 kafka-console-consumer --bootstrap-server broker3:29094 --topic kinaction_helloworld --from-beginning


CHANGING TOPIC CONFIGURATION (izmenit nastrojki topica iz cli):
kafka-configs --bootstrap-server kafka1:19092 --entity-type topics --entity-name configured-topic --describe       (configured-topic -> eto prosto imja topica dlja primera)
kafka-configs --bootstrap-server kafka1:19092 --entity-type topics --entity-name configured-topic --alter --add-config min.insync.replicas=2  (eto primer izmenenija min.insync.replicas, no on takoj zhe i dlja drugih parametrow
kafka-configs --bootstrap-server kafka1:19092 --entity-type topics --entity-name configured-topic --alter --delete-config min.insync.replicas  (eto primer izmenenija min.insync.replicas, no on takoj zhe i dlja drugih parametrow)

########################################################################################################################################################################################

wurstmeister/kafka ordner 'config' place	->	/opt/kafka/config
wurstmeister/kafka kafka-topics place		->	/opt/kafka/bin/kafka-topics.sh
comandi wipolnjat iz papki 'bin'			->	bin/kafka-topics.sh --zookeeper zookeeper:2181 --list

########################################################################################################################################################################################

RAZDEL PRODUCER:

batch.size	->	У producer есть буферы(bufferes) записей(records) для каждого раздела(partition) темы(topic), размер которых определяется свойством batch.size.
			Чем меньше размер пакета(batch size), тем меньше пропускная способность, и если размер пакета(batch size) слишком велик, память будет потрачена впустую,
			поскольку эта часть памяти выделена для пакетной обработки(batching). Default value is batch-size: 16384 KB.
			Это связано с тем, что данные будут отправлены до достижения предела размера пакета(batch size).
			Использование большего размера пакета(batch size) делает сжатие(compression) более эффективным,
			и если данные больше, чем размер пакета(batch size), они не будут пакетироваться(batched).
batch.size.boost.factor	->	tune for higher throughput(dopolnitelnaja nastrojka dlja batch.size), ego mozhno menjat i smotret kakoe luchsche podohid dlja moego scenarija.


linger.ms	->	При большой нагрузке данные, скорее всего, будут группироваться(batched). Однако при небольшой нагрузке данные не могут быть сгруппированы(batched).
			В этом случае увеличение свойства linger.ms может увеличить пропускную способность за счет увеличения пакетной обработки(batched) с меньшим количеством запросов
			и увеличением задержки(latency) при отправке поставщиком(producer). W obschih slowah - dobawljaet zaderzhku, esli nagruzka ne bolschaja, eto ubelichiwaet
			propusknuju sposobnost.

max.in.flight.requests.per.connection	->	Буферы отправляются так быстро, как может поддерживать брокер.
								И это может быть ограничено свойством max.in.flight.requests.per.connection, и если оно установлено в 1,
								любой последующий запрос на отправку будет ожидать результата возврата предыдущего.

ack=all	->	По умолчанию производитель(producer) будет ждать, пока все реплики(replicas) вернут результат,
			поскольку значение по умолчанию для свойства подтверждения(acknowledge) равно ack=all.
			Установив ack=1, только брокер, получивший запрос, отправит подтверждение(confirmation) вместо ожидания всех синхронизированных реплик.
			Esli ustanowit na ack=0, producer ne budet zhdat otweta wowse.

producer config property:
compression.type	->	Свойство производителя(producer) compression.type позволяет установить сжатие(compression) на уровне производителя(producer).
				Значение по умолчанию — none.
				Этот параметр может иметь значение none, gzip, snappy(compression library from google - bistree no ne daet takogo silnogo szhatija kak drugie warianti) или lz4.
				Сжатие(compression) выполняется пакетно(batch) и улучшается с увеличением размера пакета(batch).
end-to-end-compression	->	Сквозное сжатие(end-to-end-compression) также возможно, esli в конфигурации Kafka Broker
					для параметра(config) compression.type установлено значение производителя(producer).
					Затем сжатые данные будут отправлены производителем, затем переданы в тему(topic) и возвращены любому потребителю(consumer) в сжатом формате.
					Таким образом, сжатие(compression) происходит только один раз и повторно используется брокером и потребителем.

swoja properti:
request.timeout	->	mozhno nastroit, chto esli cherez opredelennoe wremja posle otprawki message v topic, producer ne poluchil podtwerzhdenie, budet kinut exception.
swoja properti:
retry.count	->	producer popitaetsja esche ukazannoe chislo raz otoslat message, w sluchae oschibki


producer config property:
request.timeout.ms	->	Свойство конфигурации producer имеет значение request.timeout.ms по умолчанию 30 секунд.
					Это свойство клиента(client), которое заставляет клиента ждать столько времени, пока сервер ответит на запрос.

producer config property:
retries	->	Повторные попытки(retries) свойства конфигурации производителя(producer) заставляют повторять запрос, если производитель не получает подтверждение от брокера kafka.
			По умолчанию он равен 0. Pri znachenii bolee 0, mozhet proizojti poterja porjadka soobschenij.(v pobtorjajuschemsja soobschenii mozhet okazatsja i sledujuschee
			za nim soobschenie)
					Chtobi izbeschat etogo, nuzhno:
					esli retries > 0
					nuzhno nastroit
					max.in.flyght.requests.per.connection = 1
					tak porjadok sohranitsja, tak kak sledujuschee za nim soobschenie budet zhdat, poka eto wse zhe budet otprawlenno

producer config property:
partitioner.class	->	Свойство конфигурации производителя partitioner.class задает стратегию разделения(partition strategy).
				По умолчанию для параметра partitioner.class задано значение org.apache.kafka.clients.producer.internals.DefaultPartitioner(RoundRobin approach)

################################################################################################################################################################################

RAZDEL CONSUMER:

batch-listener		->	goworim, chto hotim poluchit dannie ot kafka ne po odnoj zapisi a partijami (batch)

auto-start-up		->	etim znacheiem ja mogu skazat, nachat srazu zhe consuming ili popozsche

concurrency-level		->	Spring sozdast threads imenno dlja consuming dannih, eto znachenie dolzhno bit ravno kolichestvu partitions v kafka

poll-timeout		->	opredeljaet kak dolgo mi budem zhdat, poka ne budet dostupna hotja bi odna zapis, budet blokirowat method i zhdat nowoj zapisi (rekomendowanno ca. 100)

################################################################################################################################################################################

linux read file							->	cat <file name>
linux create and write file(Ctrl+D to save file)	->	cat > <file name>
linux delete file							->	rm <file name>

