(1) definition of schema for kafka connect worker instance
        - technologists-schema.json

(2) configuration for a kafka connector worker -> technologists-source-connector.json
        - used the lastName field as a key for kafka record : "schema.keyfield": "lastName"
        - posilaet soobschenija v kafka kazhduju secundu    : "max.interval": 1000,
        - max chislo wseh poslannih soobschenij             : "iterations": 1000,

(3) cli-tools create topic
            docker exec -it cli-tools kafka-topics --bootstrap-server kafkaBroker1:29092 --create --topic technologists --partitions 3 --replication-factor 3
        or without cli-tool
            docker exec -it kafkaBroker1 kafka-topics --bootstrap-server kafkaBroker1:29092 --create --topic technologists --partitions 3 --replication-factor 3
        or
            in cli docker container direct

(4) send the worker config to the kafka connector
        curl -i -H "Content-Type: application/json" -X PUT http://localhost:8083/connectors/technologists/config --upload-file technologists-source-connector.json

########################################################################################################################

check with own cli kafka consumer
    docker exec -it schema-registry kafka-avro-console-consumer --bootstrap-server kafkaBroker1:29092 --topic technologists --from-beginning --property "schema.registry.url=http://localhost:8081" --group first_consumer_group
cli-tools all topics
    docker exec -it cli-tools kafka-topics --bootstrap-server kafkaBroker1:29092 --list

########################################################################################################################

CURL connector:
- send the worker config to the kafka connector:
    curl -i -H "Content-Type: application/json" -X PUT http://localhost:8083/connectors/technologists/config --upload-file technologists-source-connector.json
- to fetch all already installed connector plugins:
    curl -i http://localhost:8083/connector-plugins
- show the status from connector:
    curl -i http://localhost:8083/connectors/technologists/status
- paused the kafka connect:
    curl -i -X PUT http://localhost:8083/connectors/technologists/pause
- startowat zanovo the kafka connect:
    curl -i -X PUT http://localhost:8083/connectors/technologists/resume
- delete the kafka connect:
    curl -i -X DELETE http://localhost:8083/connectors/technologists

########################################################################################################################

random creating the data
    - https://github.com/confluentinc/avro-random-generator

########################################################################################################################

ElasticSearch kafka connector specific configuration
    https://docs.confluent.io/kafka-connectors/elasticsearch/current/configuration_options.html#elasticsearch-sink-connector-configuration-properties

########################################################################################################################

elasticsearch (for 8.*.* version):
    - reset password in elasticsearch for user 'elastic' in docker container elasticsearch go to -> /bin , command -> elasticsearch-reset-password -u elastic , danach sieht man den neuen password (when without env variable in docker compose)
    - docker cp elasticsearch:/usr/share/elasticsearch/config/certs/http_ca.crt .
    - curl --cacert http_ca.crt -u elastic https://localhost:9200
    - password eingeben


elasticsearch GET all:

GET technologists-topic/_search
{
    "query": {
        "match_all": {}
    }
}

########################################################################################################################

kafka confluent all connectors properties:
    https://docs.confluent.io/kafka-connectors/self-managed/kafka_connectors.html#kafka-connectors